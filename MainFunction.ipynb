{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function,division\n",
    "import sys\n",
    "sys.path.append('/home/oem/vision')\n",
    "sys.path.append('/home/oem/miniconda3/lib/python3.9/site-packages/skimage')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from os.path import  join\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.optim.lr_scheduler import ExponentialLR as ExponentialLR\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import medpy\n",
    "import PIL\n",
    "import json\n",
    "\n",
    "from TMSNet_4Decoders_Train_Test import train, test\n",
    "from TMSNet_4Decoders import TMSNet_4Decoders\n",
    "import pdb\n",
    "\n",
    "from DataLoader import get_data\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device=torch.device(\"cuda:1\")  \n",
    "\n",
    "class option:\n",
    "    def __init__(self,PathToSaveTrainedModels,Dataset,device=torch.device(\"cuda:0\")):\n",
    "        \n",
    "        \n",
    "        self.Dataset=Dataset       \n",
    "        if self.Dataset=='Atrium2018':\n",
    "            self.InputSize = 128           \n",
    "            self.weight_decay=0.001 \n",
    "            self.batchSize=8\n",
    "        elif self.Dataset=='Atrium2013':\n",
    "            self.InputSize = 192\n",
    "            self.weight_decay=0.001 \n",
    "            self.batchSize=8 \n",
    "        elif self.Dataset=='PrivateDataset':\n",
    "            self.InputSize = 192\n",
    "            self.weight_decay=0.001 \n",
    "            self.batchSize=8             \n",
    "        elif self.Dataset=='DRIVE':\n",
    "            self.InputSize = 192*3\n",
    "            self.weight_decay=0.001 \n",
    "            self.batchSize=1  \n",
    "        elif self.Dataset=='IOSTAR':\n",
    "            self.InputSize = 192*3\n",
    "            self.weight_decay=0.001 \n",
    "            self.batchSize=1    \n",
    "        elif self.Dataset=='STARE':\n",
    "            self.InputSize = 192*3\n",
    "            self.weight_decay=0.001 \n",
    "            self.batchSize=1             \n",
    "\n",
    "            \n",
    "        self.lr =0.0005 \n",
    "        self.cuda = True\n",
    "        self.nEpochs = 100\n",
    "        self.gammaForScheduler=0.95 \n",
    "        self.FolderName='8'\n",
    "        self.threads=0\n",
    "        self.testBatchSize=1\n",
    "        self.PathToSaveTrainedModels=PathToSaveTrainedModels\n",
    "        self.device=device\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "class TrainingParameters:\n",
    "    def __init__(self,device,training_data_loader_All,training_data_loader_1,training_data_loader_2,training_data_loader_3,training_data_loader_4,val_data_loader_All,val_data_loader_1,val_data_loader_2,val_data_loader_3,val_data_loader_4,testing_data_loader):\n",
    "        \n",
    "        self.initial_seed=23789 \n",
    "        self.training_data_loader_All=training_data_loader_All\n",
    "        self.training_data_loader_1=training_data_loader_1\n",
    "        self.training_data_loader_2=training_data_loader_2\n",
    "        self.training_data_loader_3=training_data_loader_3\n",
    "        self.training_data_loader_4=training_data_loader_4\n",
    "             \n",
    "        self.val_data_loader_All=val_data_loader_All           \n",
    "        self.val_data_loader_1=val_data_loader_1\n",
    "        self.val_data_loader_2=val_data_loader_2\n",
    "        self.val_data_loader_3=val_data_loader_3\n",
    "        self.val_data_loader_4=val_data_loader_4\n",
    "        self.testing_data_loader=testing_data_loader\n",
    "        self.device=device\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint(epoch):\n",
    "    model_out_path = join(opt.PathToSaveTrainedModels,\"epoch_{}.pth\".format(epoch))\n",
    "    torch.save(model.state_dict(), model_out_path)\n",
    "    \n",
    "    \n",
    "    fig, [ax1,ax2] = plt.subplots( nrows=1, ncols=2 )  # create figure & 1 axis\n",
    "    ax1.plot(trainingLoss)\n",
    "    ax1.set(xlabel='epochs', ylabel='TrainingLoss')  \n",
    "    ax2.plot(validationLoss)\n",
    "    ax2.set(xlabel='epochs', ylabel='ValidationLoss')  \n",
    "\n",
    "    plt.savefig(join(opt.PathToSaveTrainedModels,\"ErrorPlot_{}_Epoch.png\".format(epoch)))\n",
    "    plt.show()\n",
    "    plt.close(fig)     \n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestForNoisyInput(attacks,opt,TranPara,model,device,method,noise,TestDataset):\n",
    "    for AttackType in attacks:#['Rician']: #,'Gaussian'\n",
    "        opt.AttackType=AttackType\n",
    "\n",
    "        if opt.AttackType=='Rician':\n",
    "            noiseRange= [15,25,10,5,20]\n",
    "        elif opt.AttackType=='Gaussian':\n",
    "            noiseRange=[1,5,25,10,15,20]\n",
    "\n",
    "        else:\n",
    "            noiseRange=[0.01,0.02,0.03,0.04]\n",
    "\n",
    "        for epsilon in noiseRange:\n",
    "\n",
    "            test(TranPara,opt,model, device,epsilon=epsilon,method=method,noise=noise,TestDataset=TestDataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "\n",
    "\n",
    "    model=TMSNet_4Decoders(W=6).to(device) # W=8 for STACOM 2013, W=6 for DRIVE and the private dataset\n",
    "    \n",
    "    ## update paths accordingly for your computer\n",
    "    PathToSaveTrainedModels= ---- PathToSaveTrainedModels-------\n",
    "    \n",
    "    \n",
    "    \n",
    "    Dataset='Atrium2013'\n",
    "    #MainFolder='2013' # a subfolder of Dataset \n",
    "    \n",
    "    \n",
    "    opt=option(PathToSaveTrainedModels,Dataset,device)\n",
    "    optimizer  =optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=opt.lr) \n",
    "    scheduler=ExponentialLR(optimizer,gamma=opt.gammaForScheduler) \n",
    "    \n",
    "    \n",
    "    dataPath= ---PathToDataFolder----  ##\"/home/oem/Desktop/TMS-Net/ekler/Datasets/Atrium2013/\"\n",
    "    \n",
    "    \n",
    "    train_set=get_data(opt,dataPath,DataloaderType='training',Module='Encoder')\n",
    "    training_data_loader_All = DataLoader(dataset=train_set, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=True,drop_last=False)\n",
    "\n",
    "    val_set = get_data(opt,dataPath,DataloaderType='validation')\n",
    "    val_data_loader_All = DataLoader(dataset=val_set, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_set = get_data(opt,dataPath,DataloaderType='training',Module='')\n",
    "    training_data_loader_1 = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True,pin_memory=False,drop_last=False)\n",
    "\n",
    "    val_set = get_data(opt,dataPath,DataloaderType='validation')\n",
    "    val_data_loader_1 = DataLoader(dataset=val_set, num_workers=0, batch_size=opt.batchSize, shuffle=True,pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    test_set =get_data(opt,dataPath,DataloaderType='test') \n",
    "    testing_data_loader= DataLoader(dataset=test_set, num_workers=0, batch_size=opt.testBatchSize, shuffle=False,pin_memory=False)\n",
    "\n",
    "   \n",
    "    TranPara=TrainingParameters(device,training_data_loader_All,training_data_loader_1,training_data_loader_1,training_data_loader_1,training_data_loader_1,val_data_loader_All,val_data_loader_1,val_data_loader_1,val_data_loader_1,val_data_loader_1,testing_data_loader)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "it=0\n",
    "\n",
    "trainingLoss=[]\n",
    "validationLoss=[]\n",
    "\n",
    "epsilon=0\n",
    "## 30 epochs for STACOM 2013\n",
    "#model.load_state_dict(torch.load(os.path.join(PathToSaveTrainedModels,'epoch_6.pth')), strict= False)\n",
    "\n",
    "\n",
    "TestDataset=Dataset\n",
    "\n",
    "\n",
    "for epoch in range(opt.nEpochs):\n",
    "\n",
    "\n",
    "    model,optimizer, trainLoss, valLoss= train(TranPara,opt,model,epoch,optimizer)\n",
    "    trainingLoss.append(trainLoss)\n",
    "    validationLoss.append(valLoss)\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    it=it+1\n",
    "    print(\"TrainingEpoch:\"+str(it))\n",
    "    if epoch%1 == 0:\n",
    "        checkpoint(epoch)\n",
    "    if epoch%1 == 0 and epoch>500:\n",
    "\n",
    "        test(TranPara,opt,model,device,TestDataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in methods:\n",
    "    from QualityEstimation import QualityEstimationCorrected , DoAll\n",
    "    Dataset='Atrium2013'\n",
    "    Attacks=['Rician']\n",
    "    print(method)\n",
    "\n",
    "    mainPathTraining='....... /onTrainingData/'+method # path to Json files saved for training images\n",
    "    mainPathTest='......../onTestData/'+method # path to Json files saved for test images\n",
    "    mainPath=mainPathTest\n",
    "    DoAll(Dataset,mainPath,mainPathTraining,mainPathTest,Attacks,ignoreZero=True) #True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example code to generate noisy input images for Atrium2013 datasets for a model trained with Atrium2013 dataset.\n",
    "attacks=['Rician'] \n",
    "TestDataset='Atrium2013'\n",
    "noise=True\n",
    "TranPara.testing_data_loader= ....... # change it according to test set path\n",
    "TestForNoisyInput(attacks,opt,TranPara,model,device,method,noise,TestDataset):\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
